Intro
Concatenating datasets
Tranposing multiple columns into single column
Tranposing single column into multiple columns
Tranposing rows into column and column into rows
Cross Tabluted reports
Quiz
assignment
Resources

intro
=====
In general,We see how to structure our data leading to the four rules defining a tidy dataset:

1)Each variable has its own column
2)Each observation has its own row
3)Each value must have its own cell
4)Each type of observational unit forms a table

Concatenating datasets
=====================
At the high level, there are two ways you can merge datasets; you can add information by adding more rows or by adding more columns to your dataset. 
In general, when you have datasets that have the same set of columns or have the same set of observations,
you can concatenate them vertically or horizontally, respectively. Let's learn by seeing some examples.

Adding datasets horizontally(Columns)
-------------------------------------
-When you have datasets representing the same set of observations, you can concatenate such datasets horizontally.
-The cbind function – short for column bind – is a merge function that can be used to combine two data frames with the same number of multiple rows into a single data frame

df1 = data.frame(
  StudentId = c(101:106),
  Product = c(
    "Hindi",
    "English",
    "Maths",
    "Science",
    "Political Science",
    "Physics"
  )
)
df1 


df2 = data.frame(versionType = c("pdf","book","pdf","epub","pdf","title"))
df2 

cbind(df1,df2)

Adding datasets vertically(rows)
-------------------------------
-When you have multiple datasets that have the same set of columns, you can concatenate one dataset to another,vertically.
-Rbind can be used to append two dataframes with the same number of columns together

df1 = data.frame(
  StudentId = c(101:106),
  Product = c(
    "Hindi",
    "English",
    "Maths",
    "Science",
    "Political Science",
    "Physics"
  )
)
df1 

#We will build on the example we started with cbind, the column bind function
new <- cbind(StudentId=c(200,201,202),
             Product=c("geometry","philosophy","chemistry"))
new            

#And we can use rbind to join the two.
total <- rbind(df1,new)
total

Tranposing multiple columns into single column
==============================================
-This is like converting Wide Format Data to Long Format
-This can be achieved using melt and gather()functions.


using melt functions
---------------------
#example -1
set.seed(123)
N <- 15
colm1  <- sample(1:15, N, replace=TRUE)
colm2  <- sample(1:15, N, replace=TRUE)
colm3  <- sample(1:15, N, replace=TRUE)
df_Temp <- data.frame(colm1, colm2,colm3)
df_Temp$id<-seq(nrow(df_Temp))
df_Temp

#it takes multiple columns of data and convert it into a single column of data
library(reshape2)
molted=melt(df_Temp,id.vars=c("id"))
molted

#example -2:
Refer Wide to Long.png
mydata = read.table(text= "ID setosa versicolor virginica
                    1 5.1 NA NA
                    2 4.9 NA NA
                    3 NA 7 NA
                    4 NA 6.4 NA
                    5 NA NA 6.3
                    6 NA NA 5.8
                    ", header=TRUE)

#The following program would reshape data from wide to long format.
library(reshape2)
x = colnames(mydata[,-1])
t = melt(mydata,id.vars = "ID",measure.vars = x , variable.name="Species", value.name="Sepal.Length",na.rm = TRUE)
t

Using gather functions - Tidyr
------------------------------
#Install and load packages
library(tidyr)
library(magrittr)

This function transforms data from wide to long format
library(tidyr)
library(magrittr)
df_Temp %>% gather(colm1,colm2,colm3,key="cols",value="points")

Construct the hogwarts1 data to do regressive operations
grf <- c(2678, 978, 23) 
sly <- c(3476, 1002, 34) 
rav <- c(2445, 889, 54) 
huf <- c(1998, 700, 12) 
activity <- c("Quiddich", "Duelling", "Potions") 
hogwarts1 <- tibble(activity, grf, sly, rav, huf)
hogwarts1
hogwarts1 %>% gather(grf, sly, rav, huf,key="house",value="points") %>% 
  group_by(house) %>% 
  summarise(av_points=mean(points)) %>% 
  slice(which.max(av_points)) %>% 
  select(house)


Tranposing  single column into multiple columns
===============================================
-This is like Convert Long to Wide Format
-This can be achieved using dcast and spread()functions.

Using dcast functions
---------------------
Using dcast function when you have a molten dataset then you can convert the molten dataset into an original format using this function
Example 1:on the above example 1 datasets
library(reshape2)
data <- read.table(text="X Y    Z
                   ID12   2012-06    566
                   ID1    2012-06  10239
                   ID6    2012-06    524
                   ID12   2012-07   2360
                   ID1    2012-07   13853
                   ID6    2012-07    2352
                   ID12   2012-08   3950
                   ID1    2012-08   14738
                   ID6    2012-08   4104",header=TRUE)

#R Code : Transform Long to Wide Format
mydt = dcast(data,X~Y,value.var = "Z")
mydt

Using spread functions
----------------------
#Install and load packages
library(tidyr)
library(magrittr)

Athlete <- c("John", "John", "Sandra", "Sandra") 
Event <- rep("Long Jump", times = 4) 
columnC <- c("Points", "Attempts", "Points", "Attempts") 
columnD <- c(10,3,3,1) 
sportsday2 <- tibble(Athlete, Event, columnC, columnD)
sportsday2

#convert int row into columns
sportsday2 %>% tibble(key='columnC',value='columnD')

Using separte functions 
----------------------
this will pulls apart multiple values in a single cell into separate cells. you can define what the separator is.

#Install and load packages
library(tidyr)
library(magrittr)

#Construct the sportsday3 data 
Athlete <- rep(c("John", "Jack", "Sandra"), each = 3) 
Event <- rep(c("Long Jump", "Javelin", "High Jump"), each = 3) 
columnC <- c("6/3", "5/2", "10/3", "5/1", "4/1", "2/1", "8/3", "7/2", "3/1") 
sportsday3 <- tibble(Athlete, Event, columnC)
sportsday3

#using the columnC for to split.
sportsday3 %>% separate(columnC, into = c("Points", "Attempts"), sep = "/")

Tranposing rows into column and column into rows
================================================
-using transform function
-It is used to change the rows into columns and columns into rows

set.seed(123)
N <- 15
colm1  <- sample(1:15, N, replace=TRUE)
colm2  <- sample(1:15, N, replace=TRUE)
colm3  <- sample(1:15, N, replace=TRUE)

df_Temp <- data.frame(colm1, colm2,colm3)
df_Temp$id<-seq(nrow(df_Temp))
df_Temp

trans <- t(df_Temp)  #columns into rows
trans

trans1 <- t(trans) #rows into columns
trans1

Cross Tabluted reports
======================

A pivoting spec is a data frame that describes the metadata stored in the column name, with one row for each column, and one column for each variable mashed into the column name

using pivottabler library
-------------------------
The pivottabler package enables pivot tables to be created and rendered/exported with just a few lines of R.
Pivot tables are constructed natively in R, either via a short one line command to build a basic pivot table or via series of R commands that gradually build a more bespoke pivot table to meet your needs.

library(pivottabler)
bhmtrains
?bhmtrains
#get the count of the train category based on 
qhpvt(bhmtrains, "TOC", "TrainCategory", "n()")
?qhpvt
unique(bhmtrains$TOC)
unique(bhmtrains$TrainCategory)
#Extending the Basic Pivot Table
pt <- PivotTable$new()
pt$addData(bhmtrains)
pt$addColumnDataGroups("TrainCategory")
pt$addColumnDataGroups("PowerType")    #    << **** CODE CHANGE **** <<
pt$addRowDataGroups("TOC")
pt$defineCalculation(calculationName="TotalTrains", summariseExpression="n()")
pt$renderPivot() #render to HTML
pt# to console

library(pivottabler)
pt <- PivotTable$new()
pt$addData(bhmtrains)
pt$addColumnDataGroups("TrainCategory")
pt$addRowDataGroups("TOC")
pt$addRowDataGroups("PowerType")    #    << **** CODE CHANGE **** <<
pt$defineCalculation(calculationName="TotalTrains", summariseExpression="n()")
pt$renderPivot()

...ctd

Ref:#https://cran.r-project.org/web/packages/pivottabler/vignettes/v00-vignettes.html

using pivot tables from dplyr
----------------------------
Pivot tables are powerful tools in Excel for summarizing data in different ways. We will create these tables using the group_by and summarize functions from the dplyr package (part of the Tidyverse).

library(tidyverse) --combinations of all packages
library(tidyr)
library(magrittr)
library(readxl)
library(here)
library(skimr) # install.packages('skimr')
library(kableExtra) # install.packages('kableExtra')

library(readxl)
#Setting the working directory
setwd("C:/Users/gbag/Downloads/pratice/pandas-Datasets/pandas-Datasets/")
getwd()

lobsters=read_xlsx("lobsters.xlsx")
lobsters2=read_xlsx("lobsters2.xlsx")

#skimr::skim =To look at summary statistics we’ve used summary
skimr::skim(lobsters)

head(lobsters)
summary(lobsters)

#group_by one variable
lobsters %>% group_by(year) %>% summarize(count_by_year=n())

#group_by multiple variables
lobsters %>% group_by(site,year) %>% summarize(count_by_year=n())

#summarize multiple variables
lobsters %>% group_by(site,year) %>% summarize(count_by_year=n(),
                                               mean_size_m=mean(size_mm))

#to excluse the above with NA, using na.rm=TRUE
lobsters %>% group_by(site,year) %>% summarize(count_by_year=n(), 
                                               mean_size_m=mean(size_mm,na.rm=TRUE),
                                               sd_size_mm=sd(size_mm,na.rm=TRUE))

site_sumary_Year <- lobsters %>% group_by(site,year) %>% summarize(count_by_year=n(), 
                                               mean_size_m=mean(size_mm,na.rm=TRUE),
                                               sd_size_mm=sd(size_mm,na.rm=TRUE))
#Table formatting with kable()
site_sumary_Year %>% kable()

#mutate :create a new variable
lobsters %>% mutate(size_m=size_mm/1000) #create single variable
lobsters %>% mutate(size_m=size_mm/1000,millenia=2000,Observer="Allison Horst") #create multiple variable

#select:select the variable
lobsters %>% select(date,site,size_mm)

Ref:
#https://rstudio-conf-2020.github.io/r-for-excel/pivot-tables.html#group_by-one-variable
#https://github.com/FunAtHome/r-workshop/blob/gh-pages/PivotTables.Rmd

using aggregate using base R
-----------------------------
To perform aggregation, we need to specify three things in the code:
-The data that we want to aggregate
-The variable to group by within the data
-The calculation to apply to the groups (what you want to find out)

library(readxl)
#Setting the working directory
setwd("C:/Users/gbag/Downloads/pratice/pandas-Datasets/pandas-Datasets/")
getwd()
lobsters=read_xlsx("employee_flipAPI.xlsx")
bigmac= read_csv("bigmac.csv")
bigmac
str(bigmac_1)

#just aggregate the list by
aggregate(bigmac,by=list(bigmac$Country),FUN=mean)
mean_bigmac<- aggregate(bigmac,by=list(bigmac$Country),FUN=mean)
mean_bigmac %>% select(Group.1,"Price in US Dollars")

#Handling missing values with the aggregate() function
aggregate(bigmac,by=list(bigmac$Country),FUN=mean,na.rm=TRUE)
mean_bigmac

#applying a function 
larg_dol <- function(x){
  if(length(x)==1)
    return(x)
  return(sort(x,decreasing = TRUE)[2])
}

agg <- aggregate(bigmac,by=list(bigmac$Date,bigmac$Country),FUN=larg_dol) %>% select(Group.1,Group.2,"Price in US Dollars")
agg

Ref:
#ref https://www.r-bloggers.com/2018/07/how-to-aggregate-data-in-r/
#https://www.journaldev.com/47761/aggregate-function-in-r     

using Pivoting in dplyr
-----------------------
This vignette describes the use of the new pivot_longer() and pivot_wider() functions. 
Their goal is to improve the usability of gather() and spread(), and incorporate state-of-the-art features found in other packages

library(tidyr)
library(dplyr)
library(readr)

library(tidyverse)
setwd("C:/Users/gbag/Downloads/pratice/Datasets")

Longer
*----*
-pivot_longer() makes datasets longer by increasing the number of rows and decreasing the number of columns
-pivot_longer() is commonly needed to tidy wild-caught datasets as they often optimise for ease of data entry or ease of comparison rather than ease of analysis

#converting the columns into rows 
#string data into columns
relig_income
write_csv(relig_income,"religion_income.csv",row.names=FALSE)
read.csv("religion_income.csv")
dim(relig_income)
str(relig_income)
relig_income %>% pivot_longer(!religion,names_to='income',values_to='count')

#Numeric data in column names
billboard
write_csv(billboard,"billboard.csv",row.names=FALSE)
dim(billboard)
str(billboard)
billboard %>% pivot_longer(cols= starts_with("wk"), #starts the variable with "wk"
                           names_to=("week"), #give a new variable name called "week"
                           values_to='rank', #aggreate using rank 
                           values_drop_na=TRUE) #drop the variable NA
#strip week into number
billboard %>% pivot_longer(cols= starts_with("wk"), #starts the variable with "wk"
                           names_to=("week"), #give a new variable name called "week"
                           names_prefix = "wk", #strip to week.
                           names_transform = list(week = as.integer),#converts week into number
                           values_to='rank', #aggreate using rank 
                           values_drop_na=TRUE) #drop the variable NA
#short cut for above problem
billboard %>% pivot_longer(cols= starts_with("wk"), #starts the variable with "wk"
                           names_to=("week"), #give a new variable name called "week"
                           names_transform = list(week = readr::parse_number),
                           values_to='rank', #aggreate using rank 
                           values_drop_na=TRUE) #drop the variable NA

#Many variables in column names
who
write.csv(who,"who.csv",row.names = FALSE)
str(who)
dim(who)

unique(who$new_ep_m014)
unique(who$country)
unique(who$newrel_f65)

#convert newrel_m2534 to diagnosis, gender and age. 
who %>% pivot_longer(
  cols = new_sp_m014:newrel_f65, #start and end of the column name
  names_to = c("diagnosis", "gender", "age"),  #defination new variable
  names_pattern = "new_?(.*)_(.)(.*)", #extract the data based on cols using regular expression
  values_to = "count" #aggregate the count
)

#gender and age to factors
who %>% pivot_longer(
  cols = new_sp_m014:newrel_f65,
  names_to = c("diagnosis", "gender", "age"), 
  names_pattern = "new_?(.*)_(.)(.*)",
  names_transform = list(
    gender = ~ readr::parse_factor(.x, levels = c("f", "m")),
    age = ~ readr::parse_factor(.x,
                                levels = c("014", "1524", "2534", "3544", "4554", "5564", "65"), 
                                ordered = TRUE
    )
  ),
  values_to = "count",
)

#Multiple observations per row
family <- tribble(
  ~family,  ~dob_child1,  ~dob_child2, ~gender_child1, ~gender_child2,
  1L, "1998-11-26", "2000-01-29",             1L,             2L,
  2L, "1996-06-22",           NA,             2L,             NA,
  3L, "2002-07-11", "2004-04-05",             2L,             2L,
  4L, "2004-10-10", "2009-08-27",             1L,             1L,
  5L, "2000-12-05", "2005-02-28",             2L,             1L,
)

family
str(family)
dim(family)

#convert the family datasets variable 
family <- family %>% mutate_at(vars(starts_with("dob")),parse_date)

family %>% pivot_longer(!family,
                        names_to =c(".value","child"),#scans the finds the value of the Prefix XXX_child_
                        names_sep ="_", #this separator splits automatically into the single columns
                        values_drop_na =TRUE) #drop the na in the datasets

#another example
anscombe
write_csv(anscombe,"anscombe.csv",row.names=FALSE)
str(anscombe)
dim(anscombe)

#converting those columns into rows
anscombe %>% pivot_longer(everything(), #all the variables in the datasets
                          names_to=c(".value","set"), #filter the similar value to single set using set keyword
                          names_pattern="(.)(.)"
                          ) %>% arrange(set)

#Duplicated column names
#Occassionally you will come across datasets that have duplicated column names
#such datasets are hard to work with in R, because when you refer to a column by name it only finds the first match
df <- tibble(id = 1:3, y = 4:6, y = 5:7, y = 7:9, .name_repair = "minimal")
df
## it automatically adds another column to the output i,e y,y,y,y into single column
df %>% pivot_longer(!id,names_to="name",values_to="value")

##A similar process is applied when multiple input columns are mapped to the same output column,
df <- tibble(id = 1:3, x1 = 4:6, x2 = 5:7, y1 = 7:9, y2 = 10:12)
df
## it automatically adds another column to the output i,e x1,x2,y1,y2 will output to x and y
df %>% pivot_longer(!id,names_to=".value",names_pattern="(.).")


wider
*---*
-pivot_wider() is the opposite of pivot_longer(): it makes a dataset wider by increasing the number of columns and decreasing the number of rows
- It’s relatively rare to need pivot_wider() to make tidy data, but it’s often useful for creating summary tables for presentation, or data in a format needed by other tools

fish_encounters 
write.csv(fish_encounters,"fish_encounters.csv",row.names = FALSE)

##analyse this data need it in a form where each station is a column
fish_encounters %>% pivot_wider(names_from =station, #splits values to the variables
                                values_from=seen) #extract to those respective values of variables

##file the above missing value to 0
fish_encounters %>% pivot_wider(names_from =station, #splits values to the variables
                                values_from=seen,#extract to those respective values of variables
                                values_fill=0 #fill the missing value to 0
                                )

##Aggregation
warpbreaks
str(warpbreaks)
dim(warpbreaks)

warpbreaks1 <- warpbreaks %>% as_tibble() %>% select(wool,tension,breaks)
warpbreaks1
#now aggreagate like count
warpbreaks1 %>% count(wool,tension)

##aggregate based on levels on woods against breaks
warpbreaks1
unique(warpbreaks1$wool)
warpbreaks1 %>% pivot_wider(names_from = wool,
                            values_from=breaks,
                            values_fn=list(breaks=mean))

##Generate column name from multiple variables
production <- expand_grid(
  product = c("A", "B"), 
  country = c("AI", "EI"), 
  year = 2000:2014
)

prod1 <-production %>% filter(product=="A" & country=="B" | product=="B") %>% mutate(production=rnorm(nrow(.)))
prod1
str(prod1)
dim(prod1)
summary(prod1)

##We want to widen the data so we have one column for each combination of product and country
prod1 %>% pivot_wider(names_from = c(product,country),
                      values_from=production)
##customize the columna name_from
prod1 %>% pivot_wider(names_from = c(product,country),
                      values_from=production,
                      names_glue="Prod_{product}_{country}")

##Tidy census
us_rent_income
?us_rent_income
str(us_rent_income)
dim(us_rent_income)
us_rent_income %>% pivot_wider(names_from=variable,values_from=c(estimate,moe))

##Contact list
contacts <- tribble(
  ~field, ~value,
  "name", "Jiena McLellan",
  "company", "Toyota", 
  "name", "John Smith", 
  "company", "google", 
  "email", "john@google.com",
  "name", "Huxley Ratcliffe"
)

#We can fix this by noting that every contact starts with a name, so we can create a unique id by counting every time we see
contacts
contacts<- contacts %>% mutate(person_id=cumsum(field=="name"))
contacts %>% pivot_wider(names_from = field, values_from = value)

world_bank_pop
str(world_bank_pop)
dim(world_bank_pop)
write.csv(world_bank_pop,"world_bank_pop.csv",row.names = FALSE)
pop2<- world_bank_pop %>% pivot_longer('2000':'2017',names_to="year",values_to="value")
pop2

pop2 %>% count(indicator)

#split the indicator variable into few columns
pop3 <-pop2 %>% separate(indicator,c(NA,'area','variable'))
pop3

#we can complete the tidying by pivoting variable and value to make TOTL and GROW columns
#transpose rows into columns
pop3 %>% pivot_wider(names_from = variable,values_from=value)

#Multi-choice
multi <- tribble(
  ~id, ~choice1, ~choice2, ~choice3,
  1, "A", "B", "C",
  2, "C", "B",  NA,
  3, "D",  NA,  NA,
  4, "B", "D",  NA
)

multi
#convert the columns into row
multi2<- multi %>% pivot_longer(!id,values_drop_na=TRUE) %>% mutate(checked =TRUE)

#filling in the missing observations with FALSE 
multi2 %>% 
  pivot_wider(
    id_cols = id,
    names_from = value, 
    values_from = checked, 
    values_fill = FALSE
  )


longer then wider
*---------------*
world_bank_pop
str(world_bank_pop)
dim(world_bank_pop)
write.csv(world_bank_pop,"world_bank_pop.csv",row.names = FALSE)
pop2<- world_bank_pop %>% pivot_longer('2000':'2017',names_to="year",values_to="value")
pop2

pop2 %>% count(indicator)

#split the indicator variable into few columns
pop3 <-pop2 %>% separate(indicator,c(NA,'area','variable'))
pop3

#we can complete the tidying by pivoting variable and value to make TOTL and GROW columns
#transpose rows into columns
pop3 %>% pivot_wider(names_from = variable,values_from=value)

#Multi-choice
multi <- tribble(
  ~id, ~choice1, ~choice2, ~choice3,
  1, "A", "B", "C",
  2, "C", "B",  NA,
  3, "D",  NA,  NA,
  4, "B", "D",  NA
)

multi
#convert the columns into row
multi2<- multi %>% pivot_longer(!id,values_drop_na=TRUE) %>% mutate(checked =TRUE)

#filling in the missing observations with FALSE 
multi2 %>% 
  pivot_wider(
    id_cols = id,
    names_from = value, 
    values_from = checked, 
    values_fill = FALSE
  )


manuals specs
*-----------*
###Longer
##The arguments to pivot_longer() and pivot_wider() allow you to pivot a wide range of datasets. But the creativity that people apply to their data structures is seemingly endless
spec <- relig_income %>% build_longer_spec(cols=!religion,
                                   names_to="income",
                                   values_to="count")
spec
pivot_longer_spec(relig_income, spec)

###Wider
us_rent_income
spec1<- us_rent_income %>% build_wider_spec(names_from = variable,values_from=c(estimate,moe))
spec1

spec2 <- spec1 %>% mutate(.name = paste0(variable, ifelse(.value == "moe", "_moe", "")))
spec2

pivot_wider_spec(us_rent_income, spec2)

##By hand
?construction
construction
write.csv(construction,"construction.csv",row.names = FALSE)


spec <- tribble(
  ~.name,            ~.value, ~units,  ~region,     
  "1 unit",          "n",     "1",     NA,          
  "2 to 4 units",    "n",     "2-4",   NA,          
  "5 units or more", "n",     "5+",    NA,          
  "Northeast",       "n",     NA,      "Northeast", 
  "Midwest",         "n",     NA,      "Midwest",   
  "South",           "n",     NA,      "South",     
  "West",            "n",     NA,      "West",      
)

#Which yields the following longer form:
pivot_longer_spec(construction, spec)

##Theory
construction %>% pivot_longer_spec(spec) %>% pivot_wider_spec(spec)

Ref:https://tidyr.tidyverse.org/articles/pivot.html#introduction-1
Quiz
====

Assignment
==========


Resources:
=========
Ref:https://rpubs.com/Mentors_Ubiqum/Transpose_Dataframe
https://www.datacamp.com/community/tutorials/data-reshaping-in-r
https://www.listendata.com/2016/01/transpose-data-in-r.html